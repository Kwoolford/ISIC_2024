{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1588cfe7",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-08-28T02:34:03.497712Z",
     "iopub.status.busy": "2024-08-28T02:34:03.497418Z",
     "iopub.status.idle": "2024-08-28T02:34:03.502239Z",
     "shell.execute_reply": "2024-08-28T02:34:03.501468Z"
    },
    "papermill": {
     "duration": 0.012249,
     "end_time": "2024-08-28T02:34:03.504155",
     "exception": false,
     "start_time": "2024-08-28T02:34:03.491906",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "# import numpy as np # linear algebra\n",
    "# import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/working'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# print('Directory Searched')        \n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8327b2c3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T02:34:03.512744Z",
     "iopub.status.busy": "2024-08-28T02:34:03.512450Z",
     "iopub.status.idle": "2024-08-28T02:34:10.735753Z",
     "shell.execute_reply": "2024-08-28T02:34:10.734766Z"
    },
    "papermill": {
     "duration": 7.230138,
     "end_time": "2024-08-28T02:34:10.738162",
     "exception": false,
     "start_time": "2024-08-28T02:34:03.508024",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import time\n",
    "import h5py\n",
    "import base64\n",
    "import logging\n",
    "import hashlib\n",
    "import pickle\n",
    "import multiprocessing\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.metrics import f1_score, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "import imblearn\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision.models import resnet50, ResNet50_Weights\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "10c65a39",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T02:34:10.747515Z",
     "iopub.status.busy": "2024-08-28T02:34:10.747003Z",
     "iopub.status.idle": "2024-08-28T02:34:10.775504Z",
     "shell.execute_reply": "2024-08-28T02:34:10.774658Z"
    },
    "papermill": {
     "duration": 0.035155,
     "end_time": "2024-08-28T02:34:10.777321",
     "exception": false,
     "start_time": "2024-08-28T02:34:10.742166",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.DEBUG,\n",
    "                    format='(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "                    handlers=[logging.StreamHandler()])\n",
    "\n",
    "# Data paths and parameters\n",
    "TRAIN_METADATA_PATH = \"/kaggle/input/isic-2024-challenge/train-metadata.csv\"\n",
    "TRAIN_IMAGE_DIR = '/kaggle/input/isic-2024-challenge/train-image.hdf5'\n",
    "\n",
    "SUBMISSION_METADATA_PATH = '/kaggle/input/isic-2024-challenge/test-metadata.csv'\n",
    "SUBMISSION_IMAGE_PATH = '/kaggle/input/isic-2024-challenge/test-image.hdf5'\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "OVERSAMPLING_RATIO = 0.1 # .1 = 1:10, .2 = 1:5\n",
    "    \n",
    "# Due to different datatype, need to separate features for processing\n",
    "FEATURES = ['age_approx', 'sex', 'anatom_site_general', 'clin_size_long_diam_mm', 'image_type', 'tbp_tile_type']\n",
    "NUMERIC_FEATURES = ['age_approx', 'clin_size_long_diam_mm']\n",
    "CATEGORICAL_FEATURES = ['sex', 'anatom_site_general', 'image_type', 'tbp_tile_type']\n",
    "\n",
    "def load_and_preprocess_metadata(metadata_path):\n",
    "    \"\"\"Loads and preprocesses the metadata.\"\"\"\n",
    "    df = pd.read_csv(metadata_path, low_memory=False)\n",
    "\n",
    "    if 'isic_id' not in df.columns:\n",
    "        raise ValueError(\"CSV file does not contain 'isic_id' column\")\n",
    "\n",
    "    # Fill missing values\n",
    "    df['age_approx'] = df['age_approx'].fillna(df['age_approx'].mean())\n",
    "    df['sex'] = df['sex'].fillna('unknown')\n",
    "    df['anatom_site_general'] = df['anatom_site_general'].fillna('unknown')\n",
    "\n",
    "    return df\n",
    "\n",
    "\n",
    "# Prepare features using the existing encoder\n",
    "def prepare_features(df, encoder):\n",
    "    \"\"\"Prepares features for the model.\"\"\"\n",
    "    df[NUMERIC_FEATURES] = df[NUMERIC_FEATURES].fillna(df[NUMERIC_FEATURES].mean())\n",
    "\n",
    "    # One-hot encode categorical features using the pre-fitted encoder\n",
    "    encoded_features = encoder.transform(df[CATEGORICAL_FEATURES])\n",
    "    encoded_feature_names = encoder.get_feature_names_out(CATEGORICAL_FEATURES)\n",
    "\n",
    "    # Combine numeric and encoded features\n",
    "    all_feature_names = NUMERIC_FEATURES + list(encoded_feature_names)\n",
    "    feature_array = np.hstack((df[NUMERIC_FEATURES].values, encoded_features))\n",
    "    features_df = pd.DataFrame(feature_array, columns=all_feature_names)\n",
    "    \n",
    "    return features_df, all_feature_names\n",
    "\n",
    "# Define the Dataset class\n",
    "class SkinLesionDataset(Dataset):\n",
    "    def __init__(self, hdf5_file, metadata_df, features_df, features, transform=None, return_target=True, use_cache=True, cache_dir='./dataset_cache'):\n",
    "        self.hdf5_file = h5py.File(hdf5_file, 'r')\n",
    "        self.dataframe = metadata_df\n",
    "        self.features_df = features_df\n",
    "        self.all_features_names = all_features\n",
    "        self.transform = transform\n",
    "        self.use_cache = use_cache\n",
    "        self.cache_dir = cache_dir\n",
    "        self.return_target = return_target\n",
    "\n",
    "        if self.use_cache:\n",
    "            os.makedirs(self.cache_dir, exist_ok=True)\n",
    "\n",
    "        self.logger = logging.getLogger(__name__)\n",
    "        self.logger.setLevel(logging.DEBUG)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        try:\n",
    "            if self.use_cache:\n",
    "                cache_path = self._get_cache_path(idx)\n",
    "                if os.path.exists(cache_path):\n",
    "                    item = self._load_from_cache(cache_path)\n",
    "                    return item if self.return_target else item[:2]\n",
    "                else:\n",
    "                    # Load and save to cache\n",
    "                    item = self._load_item(idx)\n",
    "                    self._save_to_cache(cache_path, item)\n",
    "                    return item\n",
    "            else:\n",
    "                # Caching disabled, just load and transform\n",
    "                return self._load_item(idx)\n",
    "        except Exception as e:\n",
    "            print(f\"Error getting item at index {idx}: {e}\")\n",
    "            self.logger.error(f\"Error getting item at index {idx}: {e}\")\n",
    "            raise\n",
    "\n",
    "    @staticmethod\n",
    "    def positive_transforms(image):\n",
    "        positive_transforms = transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomVerticalFlip(),\n",
    "            transforms.RandomRotation(30),\n",
    "            transforms.ColorJitter(brightness=0.2,\n",
    "                                   contrast=0.2, saturation=0.2, hue=0.1)\n",
    "        ])\n",
    "        return positive_transforms(image)\n",
    "    @staticmethod\n",
    "    def negative_transforms(image):\n",
    "        negative_transforms = transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.ColorJitter(brightness=0.1, contrast=0.1),\n",
    "        ])\n",
    "        return negative_transforms(image)\n",
    "    \n",
    "    def _load_item(self, idx):\n",
    "        try:\n",
    "            image_id = self.dataframe.iloc[idx]['isic_id']\n",
    "\n",
    "            # HDF5 decoding (using base64 encoding/decoding)\n",
    "            image_data = self.hdf5_file[image_id][()]\n",
    "            encoded_image_data = base64.b64encode(image_data).decode('ascii')\n",
    "            image_bytes = base64.b64decode(encoded_image_data)\n",
    "            image = Image.open(io.BytesIO(image_bytes))\n",
    "\n",
    "            # Apply the transform to the image\n",
    "            if self.transform is not None:\n",
    "                image = self.transform(image)\n",
    "\n",
    "            features = torch.tensor(self.features_df.iloc[idx].values, dtype=torch.float)\n",
    "\n",
    "            # Only return the target if it's required and exists in the dataframe\n",
    "            if self.return_target and 'target' in self.dataframe.columns:\n",
    "                target_value = self.dataframe.iloc[idx]['target']\n",
    "                target = torch.tensor(target_value, dtype=torch.long)\n",
    "                return image, features, target\n",
    "            else:\n",
    "                return image, features\n",
    "\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error loading item at index {idx}: {e}\")\n",
    "            raise\n",
    "    def _get_cache_path(self, idx):\n",
    "        filename = f\"{idx}_{self.dataframe.iloc[idx]['image_filename']}\"\n",
    "        hashed_filename = hashlib.md5(filename.encode()).hexdigest()\n",
    "        return os.path.join(self.cache_dir, f\"{hashed_filename}.pkl\")\n",
    "\n",
    "    def _save_to_cache(self, cache_path, item):\n",
    "        try:\n",
    "            with open(cache_path, 'wb') as f:\n",
    "                pickle.dump(item, f)\n",
    "        except Exception as e:\n",
    "            # self.logger.error(f\"Error Saving item to disk at index {idx}: {e}\")\n",
    "            raise\n",
    "            \n",
    "    def _load_from_cache(self, cache_path):\n",
    "        try:\n",
    "            with open(cache_path, 'rb') as f:\n",
    "                return pickle.load(f)\n",
    "        except Exception as e:\n",
    "            # self.logger.error(f\"Error loading item from cache at index {idx}: {e}\")\n",
    "            raise\n",
    "    def preload(self):\n",
    "        for i in tqdm(range(len(self)), desc='Preloading Data'):\n",
    "            _ = self[i]\n",
    "        # print(f'Preloaded {len(self)} items into cache.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9c7a9ac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T02:34:10.785791Z",
     "iopub.status.busy": "2024-08-28T02:34:10.785504Z",
     "iopub.status.idle": "2024-08-28T02:34:21.521760Z",
     "shell.execute_reply": "2024-08-28T02:34:21.520762Z"
    },
    "papermill": {
     "duration": 10.743158,
     "end_time": "2024-08-28T02:34:21.524053",
     "exception": false,
     "start_time": "2024-08-28T02:34:10.780895",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaders and datasets created successfully!\n"
     ]
    }
   ],
   "source": [
    "# Executing data preparation\n",
    "if __name__ == \"__main__\":\n",
    "    # Load and preprocess metadata\n",
    "    df = load_and_preprocess_metadata(TRAIN_METADATA_PATH)\n",
    "#     print(df.isna().sum())\n",
    "\n",
    "    # Split data into features and target\n",
    "    features_data = df[FEATURES]\n",
    "    target_labels = df['target']\n",
    "\n",
    "    # Initial train-test split (before oversampling)\n",
    "    features_train, features_temp, target_train, target_temp = train_test_split(\n",
    "        features_data, target_labels, test_size=0.25, random_state=42, stratify=target_labels\n",
    "    )\n",
    "\n",
    "    # Add an extra index column to features_train\n",
    "    features_train['original_index'] = features_train.index\n",
    "    \n",
    "    # Oversample the minority class in training set\n",
    "    oversampler = RandomOverSampler(sampling_strategy=OVERSAMPLING_RATIO, random_state=42)\n",
    "    features_train_resampled, target_train_resampled = oversampler.fit_resample(features_train, target_train)\n",
    "    \n",
    "    # Ensure that resampled data is used\n",
    "#     print(\"Length of features_train_resampled:\", len(features_train_resampled))\n",
    "#     print(\"Length of target_train_resampled:\", len(target_train_resampled))\n",
    "    \n",
    "    # Extract original indices from the oversampled features\n",
    "    original_sample_indices = features_train_resampled['original_index']\n",
    "    \n",
    "#     print(original_sample_indices.dtype)    \n",
    "#     # Check for NaN values in target_train_resampled\n",
    "#     print(target_train_resampled.isna().sum())  # Should be 0\n",
    "#     print(features_train_resampled.isna().sum())  # Check this as well\n",
    "    \n",
    "#     # Now, align 'target_train_resampled' using the 'original_sampled_indices'\n",
    "#     print(target_train_resampled.index.dtype)\n",
    "    \n",
    "    # Train-test split with stratification\n",
    "    features_train, features_temp, target_train, target_temp = train_test_split(\n",
    "        features_train_resampled, target_train_resampled, test_size=0.25, random_state=42, stratify=target_train_resampled\n",
    "    )\n",
    "    features_val, features_test, target_val, target_test = train_test_split(\n",
    "        features_temp, target_temp, test_size=0.5, random_state=42, stratify=target_temp\n",
    "    )\n",
    "\n",
    "    \n",
    "    # Print NaN checks for each prepared feature set\n",
    "#     print(f\"Train features NaN check:\\n{train_features.isna().sum()}\")\n",
    "#     print(f\"Val features NaN check:\\n{val_features.isna().sum()}\")\n",
    "#     print(f\"Test features NaN check:\\n{test_features.isna().sum()}\")\n",
    "\n",
    "#     print(f\"Train features shape: {train_features.shape}, dtype: {train_features.dtypes}\")\n",
    "#     print(f\"Val features shape: {val_features.shape}, dtype: {val_features.dtypes}\")\n",
    "#     print(f\"Test features shape: {test_features.shape}, dtype: {test_features.dtypes}\")\n",
    "\n",
    "    \n",
    "    # Image transformation\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((160, 160)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "    # Reset indices for alignment\n",
    "    features_train_resampled = features_train_resampled.reset_index(drop=True)\n",
    "    target_train_resampled = target_train_resampled.reset_index(drop=True)\n",
    "    features_val = features_val.reset_index(drop=True)\n",
    "    target_val = target_val.reset_index(drop=True)\n",
    "    features_test = features_test.reset_index(drop=True)\n",
    "    target_test = target_test.reset_index(drop=True)\n",
    "\n",
    "    # Align the 'isic_id' with the indices\n",
    "    isic_id_train = df.loc[features_train_resampled.index, 'isic_id'].reset_index(drop=True)\n",
    "    isic_id_val = df.loc[features_val.index, 'isic_id'].reset_index(drop=True)\n",
    "    isic_id_test = df.loc[features_test.index, 'isic_id'].reset_index(drop=True)\n",
    "\n",
    "    # Reconstruct DataFrames for each set\n",
    "    train_df = pd.concat([features_train_resampled, target_train_resampled, isic_id_train], axis=1)\n",
    "    val_df = pd.concat([features_val, target_val, isic_id_val], axis=1)\n",
    "    test_df = pd.concat([features_test, target_test, isic_id_test], axis=1)\n",
    "\n",
    "    # Fit encoder for datasets\n",
    "    encoder = OneHotEncoder(sparse_output=False, handle_unknown='ignore')\n",
    "    encoder.fit(train_df[CATEGORICAL_FEATURES])\n",
    "\n",
    "    # Prepare features for each split using the fitted encoder\n",
    "    train_features, all_features = prepare_features(train_df, encoder)\n",
    "    val_features, _ = prepare_features(val_df, encoder)\n",
    "    test_features, _ = prepare_features(test_df, encoder)\n",
    "\n",
    "    # Create datasets\n",
    "    train_dataset = SkinLesionDataset(TRAIN_IMAGE_DIR, train_df, train_features, all_features, transform=transform, use_cache=False, cache_dir='./train_cache', return_target = True)\n",
    "    val_dataset = SkinLesionDataset(TRAIN_IMAGE_DIR, val_df, val_features, all_features, transform=transform, use_cache=False, cache_dir='/val_cache', return_target = True)\n",
    "    test_dataset = SkinLesionDataset(TRAIN_IMAGE_DIR, test_df, test_features, all_features, transform=transform, use_cache=False, cache_dir='./test_cache', return_target = True)\n",
    "\n",
    "    # Create DataLoaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "\n",
    "    # Creating the submission dataset and dataloader\n",
    "    submission_df = load_and_preprocess_metadata(SUBMISSION_METADATA_PATH)\n",
    "    submission_features_df, submission_all_features = prepare_features(submission_df, encoder)\n",
    "\n",
    "    submission_dataset = SkinLesionDataset(\n",
    "    SUBMISSION_IMAGE_PATH, \n",
    "    submission_df, \n",
    "    submission_features_df, \n",
    "    submission_all_features, \n",
    "    transform=transform, \n",
    "    use_cache=False, \n",
    "    cache_dir='./submission_cache',\n",
    "    return_target = False\n",
    "    )\n",
    "    \n",
    "    submission_loader = DataLoader(submission_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
    "\n",
    "    print('Data loaders and datasets created successfully!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10ecbc43",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T02:34:21.533837Z",
     "iopub.status.busy": "2024-08-28T02:34:21.533198Z",
     "iopub.status.idle": "2024-08-28T02:34:21.558953Z",
     "shell.execute_reply": "2024-08-28T02:34:21.558290Z"
    },
    "papermill": {
     "duration": 0.032796,
     "end_time": "2024-08-28T02:34:21.560914",
     "exception": false,
     "start_time": "2024-08-28T02:34:21.528118",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class SkinLesionModel(nn.Module):\n",
    "    def __init__(self, num_classes, num_features):\n",
    "        super(SkinLesionModel, self).__init__()\n",
    "\n",
    "        # Image feature extractor (resnet model)\n",
    "        self.resnet = resnet50(weights=None)\n",
    "        self.resnet.fc = nn.Identity() # Remove the final fully connected layer\n",
    "    \n",
    "        # Freeze the parameters of the ResNet\n",
    "        for param in self.resnet.parameters():\n",
    "            param.requires_grad = True\n",
    "    \n",
    "        # Additional features processing\n",
    "        self.feature_fc = nn.Sequential(\n",
    "            nn.Linear(num_features, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "    \n",
    "        # Combine image features and additional features\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(2048 + 64, 512), # 2048 from ResNet50, 64 from additional features\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    def forward(self, image, features):\n",
    "        # Process image through ResNet\n",
    "        # Input shape: [batch_size, 3, 160, 160]\n",
    "        # Output shape: [batch_size, 2048]\n",
    "        image_features = self.resnet(image)\n",
    "\n",
    "        # Process additional features\n",
    "        # Input shape: [batch_size, num_features]\n",
    "        # Output shape: [batch_size, 64]\n",
    "        processed_features = self.feature_fc(features)\n",
    "\n",
    "        # Combine features\n",
    "        # Output shape: [batch_size, 2048 + 64]\n",
    "        combined_features = torch.cat((image_features, processed_features), dim=1)\n",
    "\n",
    "        # Final classification\n",
    "        # Output shape: [batch_size, num_classes]\n",
    "        output = self.classifier(combined_features)\n",
    "\n",
    "        return output\n",
    "\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10, device='cuda'):\n",
    "    model.to(device)\n",
    "    print(f'Sending model to device: {device}')\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'\\nEpoch {epoch+1}/{num_epochs}')\n",
    "        print('-' * 60)\n",
    "\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        train_positives = 0\n",
    "        train_true_positives = 0\n",
    "        train_false_positives = 0\n",
    "        train_predictions = []\n",
    "        train_targets = []\n",
    "\n",
    "        print(\"Checking Data Loader...\")\n",
    "        for i, (images, features, targets) in enumerate(train_loader):\n",
    "            if i == 0:\n",
    "                print(f'First batch loaded. Shapes: images: {images.shape}, features {features.shape}, targets {targets.shape}')\n",
    "                break\n",
    "        print(\"Data Loader Check Complete\")\n",
    "        \n",
    "        print('Training:')\n",
    "        progress_bar = tqdm(train_loader, desc='Training')\n",
    "        for batch_idx, (images, features, targets) in enumerate(progress_bar):\n",
    "            # print(f'Processing batch {batch_idx+1}/{len(train_loader)}')\n",
    "            # print(f'Images shape: {images.shape}, Features shape: {features.shape}, Targets shape: {targets.shape}')\n",
    "            images = images.to(device)\n",
    "            features = features.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images, features)\n",
    "            loss = criterion(outputs, targets.float().unsqueeze(1))\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "            predictions = (torch.sigmoid(outputs) > 0.5).squeeze()\n",
    "            train_correct += (predictions == targets).sum().item()\n",
    "            train_total += targets.size(0)\n",
    "\n",
    "            batch_positives = predictions.sum().item()\n",
    "            train_positives += batch_positives\n",
    "            train_true_positives += ((predictions == 1) & (targets == 1)).sum().item()\n",
    "            train_false_positives += ((predictions == 1) & (targets == 0)).sum().item()\n",
    "            train_false_negatives = ((predictions == 0) & (targets == 1)).sum().item()\n",
    "\n",
    "            progress_bar.set_postfix({\n",
    "                'loss': f'{loss.item():.4f}',\n",
    "                'acc': f'{train_correct/train_total:.4f}',\n",
    "                'pos_pred': f'{batch_positives}/{targets.size(0)}'\n",
    "            })\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        train_accuracy = train_correct / train_total\n",
    "        train_precision = train_true_positives / (train_positives + 1e-8)\n",
    "        train_recall = train_true_positives / (train_true_positives + train_false_negatives + 1e-8)\n",
    "        train_f1 = 2 * (train_precision * train_recall) / (train_precision + train_recall + 1e-8)\n",
    "            \n",
    "        print('\\nTraining Results:')\n",
    "        print(f'Loss: {train_loss:.4f}, Accuracy: {train_accuracy}')\n",
    "        print(f'Total Predictions: {train_total}, Positive Predictions: {train_positives}')\n",
    "        print(f'True Positives: {train_true_positives}, False Positives: {train_false_positives}')\n",
    "        print(f'Precision: {train_precision:.4f}, Recall: {train_recall:.4f}, F1: {train_f1:.4f}')\n",
    "        \n",
    "\n",
    "\n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        val_predictions = []\n",
    "        val_targets = []\n",
    "\n",
    "        with torch.no_grad():\n",
    "            progress_bar = tqdm(val_loader, desc='Validation')\n",
    "            for batch_idx, (images, features, targets) in enumerate(progress_bar):\n",
    "                images = images.to(device)\n",
    "                features = features.to(device)\n",
    "                targets = targets.to(device)\n",
    "\n",
    "                outputs = model(images, features)\n",
    "                loss = criterion(outputs, targets.float().unsqueeze(1))\n",
    "\n",
    "                val_loss += loss.item()\n",
    "                predictions = (torch.sigmoid(outputs) > 0.5).squeeze()\n",
    "                val_correct += (predictions == targets).sum().item()\n",
    "                val_total += targets.size(0)\n",
    "\n",
    "                val_predictions.extend(predictions.cpu().numpy())\n",
    "                val_targets.extend(targets.cpu().numpy())\n",
    "                \n",
    "                progress_bar.set_postfix({\n",
    "                    'loss': f'{loss.item():.4f}',\n",
    "                    'acc': f'{val_correct/val_total:.4f}'\n",
    "                })\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_accuracy = val_correct / val_total\n",
    "        val_f1 = f1_score(val_targets, val_predictions)\n",
    "        val_confusion_matrix = confusion_matrix(val_targets, val_predictions)\n",
    "\n",
    "        print(f'\\nValidation Results:')\n",
    "        print(f'Loss: {val_loss:.4f}, Accuracy: {val_accuracy:.4f}, F1: {val_f1:.4f}')\n",
    "        print('Confusion Matrix:')\n",
    "        print(val_confusion_matrix)\n",
    "        print('-' * 60)\n",
    "\n",
    "    print(\"Training Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e8be6f7e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T02:34:21.569647Z",
     "iopub.status.busy": "2024-08-28T02:34:21.569173Z",
     "iopub.status.idle": "2024-08-28T02:34:22.080421Z",
     "shell.execute_reply": "2024-08-28T02:34:22.079587Z"
    },
    "papermill": {
     "duration": 0.518086,
     "end_time": "2024-08-28T02:34:22.082705",
     "exception": false,
     "start_time": "2024-08-28T02:34:21.564619",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up Hyperparameters\n",
      "Device = cuda\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters and setup\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Setting up Hyperparameters\\nDevice = {device}\")\n",
    "\n",
    "num_classes = 1\n",
    "num_features = len(all_features)\n",
    "batch_size = 32\n",
    "num_epochs = 5\n",
    "learning_rate = 0.001\n",
    "\n",
    "# Create model, loss function, and optimizer\n",
    "model = SkinLesionModel(num_classes, num_features)\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "80afe708",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T02:34:22.092309Z",
     "iopub.status.busy": "2024-08-28T02:34:22.091612Z",
     "iopub.status.idle": "2024-08-28T05:11:15.012292Z",
     "shell.execute_reply": "2024-08-28T05:11:15.011075Z"
    },
    "papermill": {
     "duration": 9412.927575,
     "end_time": "2024-08-28T05:11:15.014436",
     "exception": false,
     "start_time": "2024-08-28T02:34:22.086861",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending model to device: cuda\n",
      "\n",
      "Epoch 1/5\n",
      "------------------------------------------------------------\n",
      "Checking Data Loader...\n",
      "First batch loaded. Shapes: images: torch.Size([32, 3, 160, 160]), features torch.Size([32, 14]), targets torch.Size([32])\n",
      "Data Loader Check Complete\n",
      "Training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10330/10330 [31:34<00:00,  5.45it/s, loss=0.0574, acc=0.9219, pos_pred=0/20]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Results:\n",
      "Loss: 0.2247, Accuracy: 0.9219145177099847\n",
      "Total Predictions: 330548, Positive Predictions: 9570\n",
      "True Positives: 6904, False Positives: 2666\n",
      "Precision: 0.7214, Recall: 1.0000, F1: 0.8382\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 1292/1292 [01:55<00:00, 11.18it/s, loss=0.3596, acc=0.9322]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Results:\n",
      "Loss: 0.2192, Accuracy: 0.9322, F1: 0.4782\n",
      "Confusion Matrix:\n",
      "[[37235   327]\n",
      " [ 2473  1283]]\n",
      "------------------------------------------------------------\n",
      "\n",
      "Epoch 2/5\n",
      "------------------------------------------------------------\n",
      "Checking Data Loader...\n",
      "First batch loaded. Shapes: images: torch.Size([32, 3, 160, 160]), features torch.Size([32, 14]), targets torch.Size([32])\n",
      "Data Loader Check Complete\n",
      "Training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10330/10330 [28:16<00:00,  6.09it/s, loss=0.1617, acc=0.9302, pos_pred=2/20]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Results:\n",
      "Loss: 0.1949, Accuracy: 0.9302219344845529\n",
      "Total Predictions: 330548, Positive Predictions: 13684\n",
      "True Positives: 10334, False Positives: 3350\n",
      "Precision: 0.7552, Recall: 0.9999, F1: 0.8605\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 1292/1292 [01:56<00:00, 11.12it/s, loss=0.3173, acc=0.9276]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Results:\n",
      "Loss: 0.2070, Accuracy: 0.9276, F1: 0.3810\n",
      "Confusion Matrix:\n",
      "[[37404   158]\n",
      " [ 2835   921]]\n",
      "------------------------------------------------------------\n",
      "\n",
      "Epoch 3/5\n",
      "------------------------------------------------------------\n",
      "Checking Data Loader...\n",
      "First batch loaded. Shapes: images: torch.Size([32, 3, 160, 160]), features torch.Size([32, 14]), targets torch.Size([32])\n",
      "Data Loader Check Complete\n",
      "Training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10330/10330 [28:51<00:00,  5.97it/s, loss=0.3473, acc=0.9314, pos_pred=1/20]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Results:\n",
      "Loss: 0.1906, Accuracy: 0.9313564141970304\n",
      "Total Predictions: 330548, Positive Predictions: 13767\n",
      "True Positives: 10563, False Positives: 3204\n",
      "Precision: 0.7673, Recall: 0.9998, F1: 0.8682\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 1292/1292 [02:02<00:00, 10.53it/s, loss=0.3387, acc=0.9306]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Results:\n",
      "Loss: 0.1799, Accuracy: 0.9306, F1: 0.4279\n",
      "Confusion Matrix:\n",
      "[[37380   182]\n",
      " [ 2684  1072]]\n",
      "------------------------------------------------------------\n",
      "\n",
      "Epoch 4/5\n",
      "------------------------------------------------------------\n",
      "Checking Data Loader...\n",
      "First batch loaded. Shapes: images: torch.Size([32, 3, 160, 160]), features torch.Size([32, 14]), targets torch.Size([32])\n",
      "Data Loader Check Complete\n",
      "Training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10330/10330 [29:03<00:00,  5.92it/s, loss=0.1061, acc=0.9315, pos_pred=2/20]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Results:\n",
      "Loss: 0.1878, Accuracy: 0.93154095623026\n",
      "Total Predictions: 330548, Positive Predictions: 13940\n",
      "True Positives: 10680, False Positives: 3260\n",
      "Precision: 0.7661, Recall: 1.0000, F1: 0.8676\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 1292/1292 [02:03<00:00, 10.50it/s, loss=0.2906, acc=0.9352]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Results:\n",
      "Loss: 0.1762, Accuracy: 0.9352, F1: 0.5277\n",
      "Confusion Matrix:\n",
      "[[37144   418]\n",
      " [ 2260  1496]]\n",
      "------------------------------------------------------------\n",
      "\n",
      "Epoch 5/5\n",
      "------------------------------------------------------------\n",
      "Checking Data Loader...\n",
      "First batch loaded. Shapes: images: torch.Size([32, 3, 160, 160]), features torch.Size([32, 14]), targets torch.Size([32])\n",
      "Data Loader Check Complete\n",
      "Training:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 10330/10330 [29:07<00:00,  5.91it/s, loss=0.2295, acc=0.9320, pos_pred=2/20]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training Results:\n",
      "Loss: 0.1869, Accuracy: 0.9320007986737175\n",
      "Total Predictions: 330548, Positive Predictions: 14078\n",
      "True Positives: 10825, False Positives: 3253\n",
      "Precision: 0.7689, Recall: 0.9998, F1: 0.8693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Validation: 100%|██████████| 1292/1292 [02:00<00:00, 10.71it/s, loss=0.3097, acc=0.9324]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation Results:\n",
      "Loss: 0.1754, Accuracy: 0.9324, F1: 0.4555\n",
      "Confusion Matrix:\n",
      "[[37354   208]\n",
      " [ 2587  1169]]\n",
      "------------------------------------------------------------\n",
      "Training Complete!\n",
      "Model saved to: ./Model_Weights/Attempt_2/submission_weights.pth\n"
     ]
    }
   ],
   "source": [
    "# # Define the save directory and path\n",
    "MODEL_SAVE_DIR = './Model_Weights/Attempt_2'\n",
    "MODEL_SAVE_PATH = os.path.join(MODEL_SAVE_DIR, 'submission_weights.pth')\n",
    "\n",
    "# Ensure the directory exists\n",
    "os.makedirs(MODEL_SAVE_DIR, exist_ok=True)\n",
    "\n",
    "# Train the model\n",
    "train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs, device)\n",
    "\n",
    "# After training is complete, save the model weights\n",
    "torch.save(model.state_dict(), MODEL_SAVE_PATH)\n",
    "\n",
    "print(f'Model saved to: {MODEL_SAVE_PATH}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "efebf966",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-08-28T05:11:33.957494Z",
     "iopub.status.busy": "2024-08-28T05:11:33.957100Z",
     "iopub.status.idle": "2024-08-28T05:11:34.591688Z",
     "shell.execute_reply": "2024-08-28T05:11:34.590546Z"
    },
    "papermill": {
     "duration": 10.170737,
     "end_time": "2024-08-28T05:11:34.594319",
     "exception": false,
     "start_time": "2024-08-28T05:11:24.423582",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_23/4177083882.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(MODEL_SAVE_PATH), strict=False)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beginning evaluation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Evaluating: 100%|██████████| 1/1 [00:00<00:00, 22.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating submission dataframe\n",
      "Submitting to CSV\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load the model and weights\n",
    "model = SkinLesionModel(num_classes=1, num_features=len(all_features))\n",
    "model.load_state_dict(torch.load(MODEL_SAVE_PATH), strict=False)\n",
    "model.eval()\n",
    "\n",
    "# Send the model to the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "print('Beginning evaluation')\n",
    "# Perform inference and generate submission.csv\n",
    "all_predictions = []\n",
    "with torch.no_grad():\n",
    "    for images, features in tqdm(submission_loader, desc=\"Evaluating\"):\n",
    "        images = images.to(device)\n",
    "        features = features.to(device)\n",
    "        outputs = model(images, features)\n",
    "        probabilities = torch.sigmoid(outputs).cpu().numpy()  # Get probability of class 1 (malignant)\n",
    "        all_predictions.extend(probabilities)\n",
    "\n",
    "print('Creating submission dataframe')\n",
    "\n",
    "# Create submission dataframe\n",
    "final_submission_df = pd.DataFrame({\n",
    "    'isic_id': submission_df['isic_id'],\n",
    "    'target': [round(float(pred[0]), 5) for pred in all_predictions]  # Ensure the target is rounded to 5 decimal places\n",
    "})\n",
    "\n",
    "print('Submitting to CSV')\n",
    "# Save to CSV\n",
    "final_submission_df.to_csv('submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b473b232",
   "metadata": {
    "papermill": {
     "duration": 9.442232,
     "end_time": "2024-08-28T05:11:53.368945",
     "exception": false,
     "start_time": "2024-08-28T05:11:43.926713",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "databundleVersionId": 9094797,
     "sourceId": 63056,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30761,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 9484.882441,
   "end_time": "2024-08-28T05:12:05.642226",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-08-28T02:34:00.759785",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
